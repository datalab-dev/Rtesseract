

A primary motivation underlying the Rtesseract package is that we need
context from the rendered page to make sense of the results of the
OCR.  Generally, we want the full location and size data for each word
or line identified by tesseract so that we can use it to intelligently
interpret the content. This includes identifying document and section
titles in the document based on the size of the text.  In this
example, we'll just look at the locations of lines on the page in
order to be able to interpret data within tables.  Again, consider the
image:

[missing]:../images/SMITHBURN_1952_p3.png

We can clearly see the data in TABLE 1 arranged by row and column.
The column headers are separated by two lines spanning the width of the text on the page.
The final 4 columns have two column headers that span all 4 columns.
The header in column 4 (NO. STRAINS ISOLATED) is on 3 separate lines but
clearly differentiated from the other data rows in the table due to the
horizontal line separating the header from the data rows.

Firstly, the tesseract() function allows us to get the horizontal and vertical locations of the words
on the page. So we could use these to attempt to recover the tabular nature of this data.
In this particular example, we can do this effectively and relatively simply. However,
in images with tables that have center-aligned columns, this is much more complicated and can
lead to ambiguity about to which column a cell belongs.
Instead, we can separate the values into their respective columns much more effectively
if we can identify the vertical lines between columns.
Similarly, we can separate the column header  cells from the data cells below
if we know the locations of the horizontal line(s) that divide them.
Furthermore, we can determine the end of the table and the continuation
of the regular text below it if we can find the final horizontal line in this example.


Given the motivation of finding the vertical and horizontal lines on the page,
let's explore how we can do this with Rtesseract.
Unfortunately, this is done outside of the OCR functionality of Rtesseract.
The OCR process tesseract performs actually identifies and removes the lines from the
image before it recognizes the remaining text on the image. This aids the accuracy of the OCR.
Unfortunately, it does not allow us to query the locations of the lines it removed.
Accordingly, we must replicate  approximately the same computations it performs to identify the
lines and their locations.
Fortunately, the basic ideas of this process are described 
(here)[http://www.leptonica.com/line-removal.html]
The Rtesseract  package provides corresponding (and higher-level convenience) functions 
to effect the same computations.

Note that we will pass the original/raw image to OCR without modifying
it. tesseract will do many of the same computations we do.
So our aim is to simply identify the locations of the horizontal and vertical lines in the
image. 
 

We start by reading the image:
```
library(Rtesseract)
f = "inst/images/SMITHBURN_1952_p3.png"

p1 = pixRead(f)
```

We immediately convert the image to gray-scale with `pixConvertTo9()`:
```
p1 = pixConvertTo8(p1)
```
(Note that this creates a new Pix and allows the previous one to be garbage collected
as we assign the new image to the same R variable.)

The next step is to correct any skew or orientation in the image.
There is a function deskew() to do this. However, we will show the steps
as they illustrate some of the leptonica functions.

To detect the skew, we must first create a separate binary image using
`pixThresholdToBinary()`.
Then we call `pixFindSkew()` and then rotate the original image
by the skew angle:
```
bin = pixThresholdToBinary(p1, 150)
angle = pixFindSkew(bin)
p2 = pixRotateAMGray(p1, angle[1]*pi/180, 255)
```
The 255 in the call to `pixRotateAMGray` corresponds to white
and means that any pixels that are "revealed" by rotating the
"page" are colored white.  We can specify any color we want here between 0 (black) and 255 (white).

It is useful to look at the resulting image:
```
pixWrite(p2, tmp <- tempfile(), IFF_PNG)
```
and then open the file named in the variable `tmp`, or
```
plot(p2)
```
(We're working on making this plot() method more general.)


With the reoriented image, we call the Rtesseract function
`getLines()`.  This performs several operations on the image
to return an image that contains either the horizontal or vertical lines.
We'll first get the horizontal lines with
```
h = findLines(p2, 51, 3)
```
We specify the Pix to process and then the horizontal width
and vertical height (in pixels) that define a window or a region.
This fills in gaps in potential lines within the region.
Leptonica moves this around and fills in gaps within it if the
rest of the pixels within the region are not white.
findLines() uses the function pixCloseGray() to do this.

Currently, findLines() returns an image (Pix object).
By default, this shows the potential lines and removes everything else.
(We can also return the image with the lines removed and the text remaining.)

`findLines()` returns a binary image containing the potential lines.
We convert this to a matrix of 0s and 1s in R:
```
m = pixGetPixels(h)
```

We can view this image with `plot(h)` or
by writing the Pix object to a file and viewing that.

We can see 4 long horizontal lines the original image that span the width of the text,
and we also see two shorter line segments above and below the text
"No. of strains isolated from".

We can find the rows of this matrix that have 1000 or more
black pixels.  We do this with
```
w = rowSums(m) > 1000
```
The value 1000 is context-specific.  It includes lines
that span 1000 pixels or more,  and also lines that have several smaller segments whose length adds up to 1000 pixels.
1000 is about 25% of the columns.  This might be too large to detect the
shorter line segments on the right of the table header.

How many rows of the matrix satisfy this criterion:
```
table(w)
```
So we have 46 which is a lot more than the 6 we see in the original image.

We can see where these horizontal lines
```
plot(h)
abline(h = nrow(m) - which(w), col = "red")
```
Note that the rows in the matrix go from 1 to nrow, while on the plot,
they go down the page. This is why we get the height with  nrow(m) - which(w).

We can see we get the 4 lines that span the width of the text area, but not the two shorter line segments.
So let's relax the threshold. We'll use 10% of the columns
```
w = rowSums(m) > .1 * ncol(m)
abline(h = nrow(m) - which(w), col = "red")
```
So we detect these two shorter lines and no others.
However, now we have 74 rows in the matrix that satisfy this criterion.
Yet we see only 6 lines on the plot.

Let's look at the row numbers for these 74 rows:
```
which(w)
```
It may not be clear, but these are grouped together.
Each of the red lines we see on the plot ise actually a collection of multiple lines.
This is clearer if we compute the different between the row numbers
```
diff(which(w))
```
We see a collection of 1s meaning that these are adjacent rows, then a large
jump between row numbers, followed by a collection of 1s and on.
So it is clear these are grouped.
We can group these lines in various ways.
One way is run length encoding (RLE):
```
rle(diff(which(w)))
```
Another way is very similar but more explicit and gives us a little more control.
We find where the differences between successive row numbers is greater than 2
and then we run a cumulative sum which gives us group labels:
```
g = cumsum( diff(which(w)) > 2 )
```

We can use g to split the rows into groups
```
rowNums = which(w)
ll = tapply(seq(along = rowNums), c(0, g), function(i) m[rowNums[i], ])
names(ll) = tapply(seq(along = rowNums), c(0, g), function(i) as.integer(mean(rowNums[i])))
```
(Note that we added 0 to the start of the vector g since g has one less element than
w since we were computing pairwise differences.)
The computation is a little akward. We split the indices of rowNums and then have
to use those to index back into rowNums to find out which rows of m we need to extract for this group.

The third line puts the average of the row numbers of each group as the name of that element.
This will be convenient for mapping this back to the general vertical area.

Each element of ll is a matrix. For each of these, we  want to combine them
to identify the start and end of a line. Each may have several separate line segments.

Lets consider the first element of ll. It has 14 rows and 4050 columns.
It is useful to query how many 0s and 1s there are?
```
table(ll[[1]])
```
These are about equal:  27000 0s and 30000 1s.
(In this setup, 1 is black.)
So there are many white pixels eventhough these appear as solid line on our plot.
But that was because we just drew a straight line at these vertical positions, regardless how how
many pixels were white. Of course, we selected these rows because they had many black pixels.

Since we think these rows make up a single line, let's aggregate them into a single row with colSums:
```
rr = colSums(ll[[1]])
```

If this is a solid line across most of the page, we'd expect most pixels to be filled with perhaps a few short
gaps.
Each element of rr contains the number of rows in this group that had a black pixel.
This might be 1 or 14, with only one row or all of them having a black pixel.
We might look at these counts or just consider whether any row has a black pixel in this column.

If we look at the vector rr, we see a lot of 0s at the beginning and the end. These are the margins where the
line is not present.
If we just threshold this to have any of the columns has a black pixel,
```
rle(rr > 0)
```
we get the two margins and a long run of 2895 pixels.
If we require at least half of the 14 rows to have a black pixel in a column,
we get the same groups:
```
rle(rr >= 7)
```


Let's consider one of the shorter lines.
These are elements 2 and 3 of ll. 
Again, we compute the column sums
```
rr = colSums(ll[[2]])
table(rr)
```
Most are 0.
There are 9 rows in this group.
So we see no columns that have at least one black pixel but less than half the number of rows.
Let's draw points at each of the columns that have a black pixel in at least half the rows
```
z = which(rr >= 4.5)
points(z, nrow(m) - rep(as.integer(names(ll)[2]), length(z)), col = "green", pch = 16)
```


So this appears to be a reasonable approach



## Vertical Lines
We can follow the same process to identify the locations
of the vertical lines. We've already deskewed  the original image,
so we don't have to do that.
We can call findLines() and this time specify a window that is tall and narrow
to capture the vertical parts.
We should experiment  with these values.
One thing to note is that characters have vertical components more than horizontal components,
e.g. 1, L, M.  If we make the height of the window too small, we'll pick up more false positives.
```
v = findLines(p2, 3, 101)
```
Again, we can plot this and see where the lines are.





# Removing the Lines
We don't have to remove the lines before we pass the image to tesseract
as tesseract will remove them for us.
However, it is interesting to see how well we can do.
Instead of finding the locations of the lines, we'll remove them from the image.
This uses the same approach, but doesn't analyze the line images, their inverse,
i.e. with the lines removed.

```
f = system.file("images", "SMITHBURN_1952_p3.png", package = "Rtesseract")
p1 = pixRead(f)
p2 = pixConvertTo8(p1)
p2 = deskew(p2)
p3 = findLines(p2, 51, 1, FALSE)
p4 = findLines(p2, 3, 101, FALSE)
p = pixAddGray(p2, p3)
p = pixAddGray(p, p4)
plot(p)
```

Let's compare this to the original image.
```
dev.new()
plot(p2)
```

We can certainly see light grey "smudges" in some places where the vertical lines were.
We also see some short horizontal line segments remaining.

We can experiment with the horizontal and vertical values we pass to findLines().
Increasing the horizontal width from 51 to 75 cleans up the horizontal lines.

We can also change the thresholds for creating the binary images.

We can also threshold the final image (p) at this point.
We set any value 50 or above to 255, i.e., white, with
```
pp = pixThresholdToValue(p, 50, 255)
```
and when we plot the resulting image
```
plot(pp)
```
the gray marks on the vertical lines have disappeared.
Note however that it removed some of the text, specifically the rotated text on the right
and the URL within that text that is colored blue in the original image.

We can compare the image we created with the lines removed to
the one tesseract creates.  We do this with
```
f = system.file("images", "SMITHBURN_1952_p3.png", package = "Rtesseract")
tesseract(f, pageSegMode = "psm_auto", textord_tabfind_show_vlines = 1)
```
This creates a PDF file named vhlinefinding.pdf.
