% !TeX root = RJwrapper.tex


% Things we should add or make certain are there 
%
% + Examples showing setting some of the options and why they matter
%   e.g. language, white list
% + Querying current options/configuration settings.
%
% + Getting the dimension of the image 
%    See  getImage.R 
% + Limiting to a particular  subregion.
%     See ./setRectangle.R and the SetRectangle example.
%
% + Setting an image after processing it in R first. Have to check this works. 
%     SetImage_raw
%

\title{Rtesseract: A package for Optical Character Recognition (OCR)
  from R}

\author{by Matthew B. Espe and Duncan Temple Lang}

\maketitle

\begin{abstract}

  % Work on this after the rest is more or less where we want it
  We describe \pkg{Rtesseract}, and R package that provides access
to Tesseract, an Open Source C++ library for Optical Character Recognition
(OCR), from within R. 
At its simplest, \pkg{Rtesseract} allows an R user to recover of text from an image
as lines, words or individual characters.
We can also obtain the location of these text elements,
possible alternatives and the predictive ``confidence'' for each.
These are often necessary for interpreting the text, e.g.,
for multicolumn layout, or tables.
The package provides access to much of the  TesseractBaseAPI, allowing full customization of OCR behavior
and also exporting the results in various formats (e.g. PDF)
and also visualizing them within R itself.
\end{abstract}

\section{Introduction}\label{intro}

<<setup, echo=FALSE, message=FALSE, warning=FALSE>>=
library(Rtesseract)
library(knitr)

# Globally set output to be limited to 4 lines
knit_theme$set("print")
opts_chunk$set(out.lines = 4)
opts_chunk$set(highlight = FALSE, background = "white", prompt = TRUE,
               comment = '')


# # the default output hook
# # From https://github.com/yihui/knitr-examples
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
    if (!is.null(n <- options$out.lines)) {
        x = unlist(stringr::str_split(x, "\n"))
        if (length(x) > n) {
            # truncate the output
            x = c(head(x, n), "....\n")
        }
        x = paste(x, collapse = "\n")  # paste first n lines together
    }
    hook_output(x, options)
})

              

@ 
There has been an enormous increase in the amount of text data that we
work with from social media, reports, scholarly articles, job applications.
These often come as plain text or structured documents such as word-processing files, 
HTML, PDF. However, there are many documents of interest that are only available as scanned images,
e.g., old books, newspapers.
Optical Character Recognition (OCR) is a technique to infer characters, words or lines of text from an image,
thereby making it accessible for data analysis.
There are many OCR software tools available, e.g., Adobe Acrobat, PDFPen Pro, ABBY.
These typically only output the results to a file. End-users are not often
given access fine scale controls, or able customize the trained
behavior of the tool.  Importantly, the results are just the text.

In response to our needs,  we developed an interface to the open source tesseract library.
Importantly, this interface provides us 1) a simple high-level 
function to extract the text from one or more images,
2) the ability to also obtain important auxiliary data,
e.g., the confidence in each prediction, the location within the image,
and 3) customization of how the OCR is done.
The results are accessible directly within R as
text and/or a data frame of locations and confidences.


This approach tightly integrates pre- and post-processing steps with the actual OCR. For example, we
can focus on a sub-region of the image, or enhance the image with some computer vision techniques
before performing the character recognition.  We can specify a domain-specific vocabulary, or
identify unconventional fonts.  The tight integration simplifies workflows that rely on invoking
stand-alone applications typically meant for human interactive use.  Also, the metadata about the
resulting text aids subsequent analyses. For example, the layout of the text into blocks, the
presence of elements such as lines or other dividers, or even the relative size of the text can all
be used to make sense of the resulting text. Diagnostic pieces of information such as the confidence
in the matches, alternative matches, etc., can be essential to improving OCR accuracy. If the OCR
tool only returns the text results, OCR's usefulness is limited to cases where the problem is either
simple or well-covered by the default setup.


\begin{comment}
Data are rarely in a form amenable to data analysis. At the extreme,
data may be inaccessible in their current form, for example in images
or scans of documents or other records. Optical Character Recognition
(OCR) is a technique to infer strings or characters from an image, thereby
converting images into a format that can be directly manipulated
by a computer program. Typically OCR is used to convert a scanned
image of a text to a digital copy, which can be of the form of a
simple text file , a structured text file (e.g., XML or HOCR), a
``search-able'' PDF document, etc.. While there are many pieces of
software with the capability to convert images of data into
computer-usable formats (e.g., Adobe Acrobat, PDFPen Pro, ABBY, etc.),
these typically only output the result file. End-users are not often
given access fine scale controls or intermedate outputs, and are not
often able customize the trained behavior of the tool.

There are a few issues with this arrangement. 
\end{comment}


Here, we describe the \pkg{Rtesseract} package, which addresses many
of the above concerns. \pkg{Rtesseract} provides an
interface to Tesseract, a fully capable, highly flexible, and open
source OCR engine. The design philosophy of the \pkg{Rtesseract}
package is to provide convenience wrappers for the OCR engine in R,
allowing ``out-of-the-box'' OCR capability while preserving access to
the fine-scale controls for more advanced use cases. Development of
\pkg{Rtesseract} began in Apr. 2015, and while there are other
packages which provide wrappers of the Tesseract command line
executable \citep{Hagmann2014}, or API \citep{ooms2016}, the
\pkg{Rtesseract} package allows additional functionality and finer
control by giving full access to the TesseractBaseAPI from within
R. \pkg{Rtesseract} supports both the current release (v3.05.01) and
development versions (v4.00.alpha) of Tesseract.

% Might need to remove this? is it really needed?
Tesseract development began at Hewlett
Packard Laboratories Bristol and Hewlett Packard Co between 1985 to
1994 \citep{Smith2007}. It was entered into 1995 UNLV Annual Test of
OCR Accuracy, where it scored well against commercial products. Little
additional development occurred between 1995 and when the code base
was released for Open Source in 2005. Since 2005, Tesseract has been
maintained by Google and open-source developers. Tesseract depends on
Leptonica, an open source program for image manipulation, processing,
and analysis. Recent developments to Tesseract include the integration
of LSTM Deep Learning networks (versions >= 4.0) for increased speed
and accuracy. An advantage of Tesseract over many commercial OCR
products is that Tesseract allows user-training to custom fonts and
languages and user-access to OCR engine control parameters, which
allows users to custom tailor the OCR engine's behavior to specific
applications (e.g., unusual fonts or languages, domain specific
vocabulary, etc.).


\section{Package Description}\label{desc}

For many simple problems, merely extracting text from an image in a
reliable manner is sufficient. \pkg{Rtesseract} provides simple
interfaces that allow users to provide the path to an image in a
supported format (tiff, JPEG, and png on most systems), and OCR will be
run on the image using the default settings. For example, say we had
an image of the first page of a scientific publication:

<<echo = FALSE>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
@ 

\begin{figure}[h]
\includegraphics[width=\textwidth]{\Sexpr{f}}
\caption{An example image of a scientific paper.}
\end{figure}

\subsection{Base Functions}

For the simplest task of retrieving the text contents of the image,
we use the high-level function
\code{GetText}. 
We pass it the path to a file containing the image
%this function will
%create a \code{TesseractBaseAPI} object, run the OCR engine, destroy
%the \code{TesseractBaseAPI} and then return the text. 
By default, it returns the words it finds in the image in the order they appear.
<<>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
GetText(f)
@

However, rather than words, we sometimes want individual characters, text-lines
or entire paragraphs. We can specify this via the \code{level} parameter.

<<>>=
GetText(f, level = "textline")

@ 
\code{GetText} therefore provides the functionality of most basic OCR applications. 

However, merely retrieving text can be of limited usefulness. Users
might wish to know the location of the match, how confident the OCR
engine is in each match, and what alternatives exist for the returned
match. For these tasks, \pkg{Rtesseract} includes three other
high-level functions: \code{GetConfidences}, \code{GetAlternatives},
and \code{GetBoxes}. Similar to \code{GetText}, these
functions can take the path of the image file 
and the optional \code{level} argument.

If we call \code{GetText} followed by another
to, e.g., \code{GetAlternatives} for the same file,
we would repeat the OCR twice on that same file.
Since this is reasonably computationally intensive, we want to perform
the OCR once and then query each of the results we want, i.e.,
the text, the confidences, the alternatives, \ldots.

%XXX So I would show the code calling tesseract() and then GetText(), GetBoxes(), GetConfidences() right now
% Then discuss why it is useful.
<<>>=
api = tesseract(f)
GetText(api)
GetBoxes(api)
GetConfidences(api)
@ 

For these cases where the user is interested in multiple pieces of
information from a single file, 
we use the \code{tesseract} function to create an instance of the OCR
engine (an object of class \code{TesseractBaseAPI} in R). 
We specify the path to the file and any other options controlling how the OCR will be performed.
We then pass this to each of the four high level functions rather than the file name. 
% It is not lazy evaluation.
By default, the call to \code{tesseract} doesn't perform the OCR immediately.
Instead, it is only done when we request any results, e.g., calling
any of the four functions above, or explicitly calling the \code{Recognize}
function with the .


For example, say we wanted to OCR the previous image, but also were
interested if the shadow on edges of the image affected the OCR
performance from left to right. Since the confidences for each match
are available to us, we can easily explore this relationship
statistically and/or visually.

% this is a bit contrived since I added shadow to the image. We could also take
% a look at the confidences at the word or character level to see
% which are causing the most issues.

%XXX Need to explain pageSegMode.  Different from level.

<<echo = FALSE>>=
api = tesseract(f)

# See if the shadow is affecting the OCR
bb = GetBoxes(api, level = "symbol")
@


<<>>=
# Group words by the center of their bounding box left to right
gg = cut(rowMeans(bb[,c(1,3)]), breaks = seq(0, max(bb[,3]), length.out = 7))
tapply(bb[,"confidence"], gg, summary)
@

\begin{figure}[h]
<<fig=TRUE, echo = FALSE>>=

scatter.smooth(bb[,5] ~ rowMeans(bb[,c(1,3)]),
     xlab = "Position of character bounding box on page",
     ylab = "Confidence (higher is more confident)",
     xaxt = "n",
     pch = 16, col = rgb(0,0,0,0.25))
axis(1, at = c(500,2000,3500), labels = c("left", "center", "right"))

@ 
\caption{An example how visualizing the confidences from the OCR
  allows investigation of how location on the page influences
  the results of the OCR engine.}
\end{figure}

Furthermore, \pkg{Rtesseract} includes a default plotting function for
OCR output for users to visually inspecting the results. We have found
these plots, which by default include the bounding boxes colored by
relative confidence overlaid over the original image (see
Fig. \ref{fig:rtess_plot} for an example), helpful in diagnosing OCR
behavior and inaccuracies. Plotting the results is especially helpful
when adjusting the OCR configuration settings (discussed below under
``Advanced Use'').

Similarly, by allowing access to information regarding the bounding
boxes, \pkg{Rtesseract} enables users to use location or size specific
information manipulate the results of the OCR. For example,
identifying the title in the above image from plain text results would
involve using context-based heuristics, but the task is far simpler
with access to information about the text size:

\begin{figure}[h]
<<echo = FALSE>>=
plot(api, fillBoxes = TRUE)
@
\caption{\pkg{Rtesseract}'s plotting function allows the user to
  overlay the original image with the bounding boxes and associated
  confidences.}
\label{fig:rtess_plot}
\end{figure}

<<>>=
# To locate the title, first get the text-line level bounding boxes
bb = GetBoxes(api, level = "textline")

# Find the tallest box for a single text line
rownames(bb)[which.max(bb[,4] - bb[,2])]

@ 

We have used the location of the bounding boxes to identify and
reconstruct text arranged in columns, separating by unrelated elements
(e.g., newspaper content), or even to reconstruct complex tabular
content. In our use, we have found using the bounding boxes preferable
to attempting to simulate the layout of the page by padding the text
with spaces (e.g., the ``layout'' output of many other OCR
engines).


\section{Advanced Use}

Thus far, we have focused on functions in \pkg{Rtesseract} which allow
for accessing and manipulating the results of running the OCR engine
on an image. In complex cases, you might want to manipulate the
behavior of the OCR engine itself rather than merely the output. For
these purposes, the \pkg{Rtesseract} packages exposes full access to
the \code{TesseractBaseAPI}, which allows fine-tuning of the OCR
engine for specific cases.

\subsection{Page Segmentation Mode and OCR Engine}

Two variables, \code{pageSegMode} and \code{engineMode}, deserve
special mention because these two can have large impact on the results of the
OCR. The first, the Page Segmentation Mode, adjusts how Tesseract
recognizes lines of text in the image. By adjusting Page Segmentation
Mode, the user can specify if the text is present in many different
configurations, including (but not limited to) single block, sparce
text, verticle or circular arrangement, etc. The \pkg{Rtesseract}
package reflects the defaults in the \code{TesseractAPI} and assumes
the input is a single block of text (\code{PSM\_SINGLE\_BLOCK}) by
default, though in our experience OCR can be significantly improved
with changing the Page Segmentation Mode. We have found for most
problems \code{PSM\_AUTO}, which attempts to detect the correct page
segmentation, is a good default, though any of the currently
\Sexpr{length(grep("^PSM_",ls('package:Rtesseract')))} available Page
Segmentation modes might be best for different applications (curiously,
\code{PSM\_AUTO} is the default for the tesseract command line tool
but not for the API). Page Segmentation Mode can be set either in the
call to \code{tesseract}, in the \code{...}  arguments for any of the
high-level functions (e.g., \code{GetText(f, pageSegMode =
"PSM\_AUTO")}), or by using \code{SetPageSegMode} on an existing
\code{TesseractBaseAPI} object.

The second of these variables is the Tesseract Engine Mode, which
determines what OCR engine is used to recognize text. By default,
\pkg{Rtesseract} uses Tesseract only. Depending on installed version
of Tesseract, other OCR engines can be used individually or in
combination with Tesseract (Cube for Tesseract versions 3.04+, LSTM for
Tesseract versions 4.00+). Although the use of these in combination
with Tesseract can increase accuracy, their use can add significant
computational load (between 6--10x) and require appropriately trained
language files, so they are not used by default by \pkg{Rtesseract}'s
OCR functions. 

\subsection{Other Variables}

There are a plethera of variables that can be adjusted, so for space
considerations we will highlight the ones we have found the most
useful in our work. To continue the example above, on inspection of
the results of the OCR there are some domain-specific terms that are
not being recognized correctly. While it might be possible to correct
these in post-processing, it is preferable to tweak the settings of
the OCR engine to alow the correct recognition in the processing
stage. The above document includes the two terms that are consistently
mis-recognized; {\it{``Ae. aegypti''}} (a scientific name) and ``São
Paulo'' (a non-English place name). \code{Tesseract} allows
user-specified words to be added to the dictionary of correct matches
through a ``user-words'' file. \pkg{Rtesseract} allows you to specify
this file, which will then be used by the OCR engine to resolve
ambiguities:

<<new>>=
# Create a user-words file for English
writeLines(c("aegypti", "São"), "eng.user-words")

# Create a new API for comparison
api2 = tesseract(f, pageSegMode="psm_auto", 
                 opts = list(user_words_file = "eng.user-words"))

# path.expand("~/DSI/Rtesseract/inst/Paper/")))

#Fixed error in OCR engine rather than post-process results
GetText(api2, "textline")[34]
GetText(api, "textline")[34]

@

Extending this idea, we can explore which characters have the lowest
confidence and/or occurence in the text.

<<>>=
symbolBB = GetBoxes(api, level = "symbol")
symbolConf = sort(tapply(symbolBB[,"confidence"], row.names(symbolBB), median))
symbolConf
@

We can visually inspect these low-confidence characters to verify that
they are correct using the \code{plotSubImage} function.

<<>>=
lowConfIdx = which(row.names(symbolBB) %in% names(symbolConf)[symbolConf < 80])
par(mfrow = c(5,5),
    omi = c(0,0,0,0),
    mai = c(1,1,1,1))

sapply(lowConfIdx, function(i, img, pad = 1)#c(0.99,1.02,1.02,0.99))
    plotSubImage(box = symbolBB[i,1:4] * pad, img = img,
                 xlab = "", ylab = "", xaxt = "n", yaxt = "n",
                 main = paste("OCRed :", row.names(symbolBB)[i])),
    img = png::readPNG(f))
idx = which(symbolBB[,"confidence"] < 75)

par(mfrow = c(7,7),
    omi = c(0,0,0,0),
    mar = c(1,1,1,1))


sapply(idx, function(i, img, pad = 1)#c(0.99,1.02,1.02,0.99))
    plotSubImage(box = symbolBB[i,1:4] * pad, img = img,
                 xlab = "", ylab = "", xaxt = "n", yaxt = "n",
                 main = paste("OCRed :", row.names(symbolBB)[i],
                              ", conf: ", symbolBB[i,"confidence"])),
    img = png::readPNG(f))

@ 


Continuing the example, say we were primarily interested in the
abstract. Using the bounding boxes or other coordinates as guides, we
are able to adjust the OCRed area without leaving R. Typically, to do
this would involve partitioning the image into subsets using an image
editing tool (e.g., Gimp, Darktable, Photoshop), and then running the
OCR on each of these subset images. This process involves leaving R
and involves steps that may be difficult to replicate. However, \pkg{Rtesseract} allows
the user to specify a rectangle of interest using the
\code{SetRectangle} function. This function takes a
\code{TesseractBaseAPI} object and the left, top, width and
height of the sub-area as additional arguments. Once set, the next
call to the \code{TesseractBaseAPI} will only recognize text within this
rectangle - no external image manipulation required. Since we know that the abstract
is between the ``Abstract'' header and the ``Keywords'' tagline, we
can easily find the coordinates of these using the bounding boxes and
then only recognize text within this area:

<<>>=
bb = GetBoxes(api)
idx = grep("Abstract|Keywords", rownames(bb))
bb[idx,"top"]
GetImageDims(api)

SetRectangle(api, 0, 950, 4000, 1800 - 950)
GetText(api, level = "textline")

#Reset rectangle
GetImageDims(api)

SetRectangle(api, 0, 0, 4013, 3210)
@ 

Many customizable variables which allow fine control of the OCR engine
are accessible through R via the \pkg{Rtesseract} package, including
pageSegMode, pageOrientation, language, white- and black-list
characters, custom user-added patterns and words, alternative OCR
engines, etc. The current settings for the tesseract OCR engine are returned by
\code{PrintVariables} (returns \Sexpr{length(PrintVariables())}
variables at the time of writing). These variables can be adjusted via
a call to \code{SetVariables}. By default, \pkg{Rtesseract} searches the
/usr/bin/local directory for installed trained language files, but
this can be overridden. The current location where the API is
searching for language data is returned by \code{GetDataPath}.
Full documentation of user-adjustable variables is
available at
\url{https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc}.

By creating persistent TesseractBaseAPI objects, two or
more \code{TesseractBaseAPI}s can be created to compare the impact of
various settings and fine tune OCR for individual cases. Once a
suitable set of adjustments have been found, the settings can be
exported using \code{PrintVariables} to be saved as an R list that can
then be handed to \code{SetVariables}.

% Looking at and changing options
<<>>=
#Querying the adjustable variables
v = PrintVariables()
v[grep("tessedit_char", names(v))]
@ 

%% Expand
%\begin{figure}[htbp]
%<<a, fig=TRUE, warning=FALSE, echo=FALSE>>=
%f = system.file("images", "1990_p44.png", package = "Rtesseract")
%ts = tesseract(f, pageSegMode = "psm_auto", ,
%              opts = list(tessedit_char_whitelist = paste(LETTERS, 0:9, " .-",
%                                                          collapse = "")))
%Recognize(ts)
%
%bb = GetBoxes(ts)
%
%quantile(bb[,"right"] - bb[,"left"], probs = seq(0,1, 0.1)) 
%
%i = bb[,"right"] - bb[,"left"] > 500
%bb[i,]
%m = plot(ts, fillBoxes = TRUE)
%rect(m[i,"left"],m[i,"bottom"],m[i,"right"],m[i,"top"], col = "red", border = NA)
%abline(v = Rtesseract:::findColumns(api = ts, ncols = 8, side = "left"))
%
%@
%\caption{An example of using the spatial information from the bounding
%  boxes to find elements on the recognized image, including lines
%  which separate parts of a table, and the location of columns.}
%\label{fig:spatial}
%\end{figure}
%

\subsection{Writing directly to file}

\pkg{Rtesseract} includes funcitonality to export the results of OCR
to many conventional file types, including BoxText, HOcr/HTML , OSD
(Orientation and Script Detection), TSV (tab separated values), and
PDF. Of these, \code{toPDF} is unique in that it creates a searchable
PDF document, not a plain-text document.

\subsection{Metadata}

Lastly, \pkg{Rtesseract} allows users to access metadata about the OCR
engine and the input image. The current version of Tesseract can
be returned by \code{tesseractVersion}, while the capabilities for
reading various image formats via leptonica is provided by
\code{leptonicaImageFormates}. Information about the source image are
also accessible through R using the \code{GetInputName},
\code{GetImageInfo},\code{GetImageDims}, and
\code{GetSourceYResolution} functions.


\section{Installation}

In order to use \pkg{Rtesseract}, users must first have both Tesseract and
its dependency, Leptonica, installed. Tesseract is available from
\url{https://github.com/tesseract-ocr/} and Leptonica from
\url{https://github.com/DanBloomberg/leptonica}. Pre-compiled binaries
are available for most platforms for the current stable version
(v3.05). As previously mentioned \pkg{Rtesseract} also works with the
development version of Tesseract (4.00alpha) currently available from
\url{https://github.com/tesseract-ocr/tesseract/releases}. However, to
build Tesseract from source requires many additional pieces of
software, including leptonica v1.74+, automake, libtool, pkg-config,
aclocal, autoheader, and autoconf-archive. Additionally, users 
will also need to install the training data for the language(s) used in the documents to be processed. 
Currently, there are pre-trained data sets for 140+ languages available from
\url{https://github.com/tesseract-ocr}. Users can also provide
their own trained data. For more information about training Tesseract,
please see
\url{https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract}. \pkg{Rtesseract}
includes some functions that assist with training, including
\code{ReadBoxFile()}. Finally, the \pkg{Rtesseract} package itself can be installed from
source at \url{https://github.com/duncantl/Rtesseract}.

% Different section title
\section{Advantages}

\pkg{Rtesseract} provides both easy access to basic OCR functionality
for simple use-cases as well as access to low-level control parameters
for more advanced uses. By allowing recovery of additional information
generated by Tesseract, such as confidence levels and bounding boxes,
\pkg{Rtesseract} supports novel applications of inputting data from
images into R (e.g., spatial analysis of text). Leveraging free,
open-source software allows full integration of the full work-flow of
text from images into R. \pkg{Rtesseract} works with both the current
stable release (3.05) and the alpha release (4.00alpha).

\bibliography{Rtesseract.bib}
