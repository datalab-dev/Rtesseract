% !TeX root = RJwrapper.tex

\title{Rtesseract: A package for Optical Character Recognition (OCR)
  from R}

\author{by Matthew B. Espe and Duncan Temple Lang}

\maketitle

\begin{abstract}

  % Work on this after the rest is more or less where we want it
  We describe \pkg{Rtesseract}, and R package that provides access
to Tesseract, an Open Source C++ library for Optical Character Recognition
(OCR), from within R. 
At its simplest, \pkg{Rtesseract} allows an R user to recover of text from an image
as lines, words or individual characters.
We can also obtain the location of these text elements,
possible alternatives and the predictive ``confidence'' for each.
These are often necessary for interpreting the text, e.g.,
for multicolumn layout, or tables.
The package provides access to much of the  TesseractBaseAPI, allowing full customization of OCR behavior
and also exporting the results in various formats (e.g. PDF)
and also visualizing them within R itself.
\end{abstract}

\section{Introduction}\label{intro}

<<setup, echo=FALSE, message=FALSE, warning=FALSE>>=
library(Rtesseract)
library(knitr)
library(RAutoGenRunTime)

# Globally set output to be limited to 4 lines
knit_theme$set("print")
opts_chunk$set(out.lines = 4)
opts_chunk$set(highlight = FALSE, background = "white", prompt = TRUE,
               comment = '')


# # the default output hook
# # From https://github.com/yihui/knitr-examples
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
    if (!is.null(n <- options$out.lines)) {
        x = unlist(stringr::str_split(x, "\n"))
        if (length(x) > n) {
            # truncate the output
            x = c(head(x, n), "....\n")
        }
        x = paste(x, collapse = "\n")  # paste first n lines together
    }
    hook_output(x, options)
})

              

@ 

Data are rarely in a form amenable to data analysis. At the extreme,
data may be inaccessible in their current form, for example in images
or scans of documents or other records. Optical Character Recognition
(OCR) technique to infer strings or characters from an image, thereby
converting images into a format that can then be directly manipulated
by a computer program. Typically OCR is used to convert a scanned
image of a text to a digital copy, which can be of the form of a
simple text file , a structured text file (e.g., XML or HOCR), a
``search-able'' PDF document, etc.. While there are many pieces of
software with the capability to convert images of data into
computer-usable formats (e.g., Adobe Acrobat, PDFPen Pro, ABBY, etc.),
these typically only output the result file. End-users are not often
given access fine scale controls and/or able customize the trained
behavior of the tool.

There are a few issues with this arrangement. First, inaccurate
results must be corrected in post-processing steps rather than
tweaking the processing itself. Images containing unique or
domain-specific vocabulary, or unconventional fonts can be completely
inscrutable to OCR running default settings intended for a common
language or font, in which case no amount of post-processing can
recover the data. Second, since these OCR tools are separate from the
environments being used to correct and subsequently analyze the
resulting data, multi-environment workflows are used which are
difficult to replicate. Third, images often contain information beyond
text which can aid subsequent analyses. For example, the layout of the
text into blocks, the presence of elements such as lines or other
dividers, or even the relative size of the text can all be used to
inform the analysis of an image. Lastly, diagnostic pieces of
information such as the confidence in the matches, alternative
matches, etc., can be essential to improving OCR accuracy. If the OCR
tool only returns the text results, OCR's usefulness is limited to
cases where the problem is either simple or well-covered by the
default setup.

% In contrast, the \pkg{Rtesseract} package has been developed to
% provide both 

% % not sure where to put this

% In addition to extracting numeric data, OCR
% allows the extraction of text, expanding corpus available for the
% increasingly powerful capacity to analyze the contents of text
% quantitatively (e.g., Natural Language Processing and Digital
% Humanities). Lastly, these tools can be used to efficiently (compared
% to human transcription) enter text from a simple image into a computer
% representation.  Here, we describe a low-level and highly expandible
% tool to extract text and data from images into R, an environment for
% statistical computing.

Here, we describe the \pkg{Rtesseract} package, which provides an
interface to Tesseract, a fully capable, highly flexible, and open
source OCR engine. The design philosophy of the \pkg{Rtesseract}
package is to provide convenience wrappers for the OCR engine in R,
allowing ``out-of-the-box'' OCR capability while preserving access to
the fine-scale controls for more advanced use cases. Development of
\pkg{Rtesseract} began in Apr. 2015, and while there are other
packages which provide wrappers of the Tesseract command line
executable \citep{Hagmann2014}, or API \citep{ooms2016}, the
\pkg{Rtesseract} package allows additional functionality and finer
control by giving full access to the TesseractBaseAPI from within
R. \pkg{Rtesseract} supports both the current release (v3.05.01) and
development versions (v4.00.alpha) of Tesseract.

% Might need to remove this? is it really needed?
Tesseract development began at Hewlett
Packard Laboratories Bristol and Hewlett Packard Co between 1985 to
1994 \citep{Smith2007}. It was entered into 1995 UNLV Annual Test of
OCR Accuracy, where it scored well against commercial products. Little
additional development occurred between 1995 and when the code base
was released for Open Source in 2005. Since 2005, Tesseract has been
maintained by Google and open-source developers. Tesseract depends on
Leptonica, an open source program for image manipulation, processing,
and analysis. Recent developments to Tesseract include the integration
of LSTM Deep Learning networks (versions >= 4.0) for increased speed
and accuracy. An advantage of Tesseract over many commercial OCR
products is that Tesseract allows user-training to custom fonts and
languages and user-access to OCR engine control parameters, which
allows users to custom tailor the OCR engine's behavior to specific
applications (e.g., unusual fonts or languages, domain specific
vocabulary, etc.).


\section{Package Motivation}\label{desc}

For many simple problems, merely extracting text from an image in a
reliable manner is sufficient. \pkg{Rtesseract} provides simple
interfaces that allow users to provide the path to an image in a
supported format (tiff, JPEG, and png on most systems), and OCR will be
run on the image using the default settings. For example, say we had
an image of the first page of a scientific publication:

<<echo=FALSE>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
@ 

\begin{figure}[h]
\includegraphics[width=\textwidth]{\Sexpr{f}}
\caption{An example image of a scientific paper.}
\end{figure}

\subsection{Base Functions}

For the simplest task of retrieving the text contents of the image,
\pkg{Rtesseract} includes the high-level function
\code{GetText}. Provided the path to an image, this function will
create a \code{TesseractBaseAPI} object, run the OCR engine, destroy
the \code{TesseractBaseAPI} and then return the text. The function
allows the user to specify multiple levels for the text to be
returned, either as single characters, words (default), text-lines, or
paragraphs. \code{GetText} therefore provides the functionality of
most basic OCR applications. 

<<>>=
GetText(f)
GetText(f, level = "textline")
@ 

However, merely retrieving text can be of limited usefulness. Users
might wish to know the location of the match, how confident the OCR
engine is in each match, and what alternatives exist for the returned
match. For these tasks, \pkg{Rtesseract} includes three other
high-level functions; \code{GetConfidences}, \code{GetAlternatives},
and \code{GetBoxes}. Similar to \code{GetText}, these
functions can take the path of the image file as a single argument,
create a \code{TesseractBaseAPI} object, run the OCR engine and
extract the information of interest, and then destroy the
\code{TesseractBaseAPI} object before returning the results to the
user.

It is easy to see the inefficiency in repeatedly creating a
\code{TesseractBaseAPI} object only to destroy it before returning the
results. For cases when the user is interested in multiple pieces of
information from a single image, the \pkg{Rtesseract} package allows
the user to create a persistent \code{TesseractBaseAPI} object using
the \code{tesseract} function which can then be handed to each of the
four high level functions rather than the file name. Due to
lazy-evaluation, the OCR engine is not actually run until invoked, but
once the image has been OCR-ed, subsequent queries for additional
information do not re-run the OCR engine but rather pull from the
previous results. This is convenient when multiple pieces of
information are needed from the same image.

For example, say we wanted to OCR the previous image, but also were
interested if the shadow on edges of the image affected the OCR
performance from left to right. Since the confidences for each match are available to us,
we can easily explore this relationship statistically and/or visually.

% this is a bit contrived since I added the image. We could also take
% a look at the confidences at the word or character level to see
% which are causing the most issues.

<<echo = FALSE>>=
api = tesseract(f, pageSegMode = "psm_auto")

# See if the shadow is affecting the OCR
bb = GetBoxes(api, level = "symbol")
@

<<>>=
# Group words by the center of their bounding box left to right
gg = cut(rowMeans(bb[,c(1,3)]), breaks = seq(0, max(bb[,3]), length.out = 7))
tapply(bb[,"confidence"], gg, summary)
@

\begin{figure}[h]
<<fig=TRUE, echo = FALSE>>=

scatter.smooth(bb[,5] ~ rowMeans(bb[,c(1,3)]),
     xlab = "Position of character bounding box on page",
     ylab = "Confidence (higher is more confident)",
     xaxt = "n",
     pch = 16, col = rgb(0,0,0,0.25))
axis(1, at = c(500,2000,3500), labels = c("left", "center", "right"))

@ 
\caption{An example of plotting how location on the page influences
  the results of the OCR engine.}
\end{figure}

Furthermore, \pkg{Rtesseract} includes plotting functions for visually
inspecting the results from OCR. These plots, which by default include
the bounding boxes colored by relative confidence overlaid over the
original image, are helpful in diagnosing OCR behavior. Plotting the
results is especially helpful when adjusting the OCR configuration
settings (discussed below under ``Advanced Use''). Similarly, by
allowing access to information regarding the bounding boxes,
\pkg{Rtesseract} enables users to use location or size specific
information manipulate the results of the OCR. For example,
identifying the title in the above image from plain text results would
involve using context-based heuristics, but the task is far simpler
with access to information about the text size:
\begin{figure}[h]
<<echo = FALSE>>=
plot(api, fillBoxes = TRUE)
@
\caption{\pkg{Rtesseract}'s plotting function allows the user to
  overlay the original image with the bounding boxes and associated
  confidences.}
\end{figure}

<<>>=
# To locate the title, first get the text-line level bounding boxes
bb = GetBoxes(api, level = "textline")

# Find the tallest box for a single text line
rownames(bb)[which.max(bb[,4] - bb[,2])]

@ 

We have used the location of the bounding boxes to identify and
reconstruct text arranged in columns, separating by unrelated elements
(e.g., newspaper content), or even to reconstruct complex tabular
content. % BB are better than padding results with spaces to simulate
         % the layout

% New Example - start with just getting text
% Look for title - need bounding boxes
% Then by lines - illustrates the need to build the api object
% rather than call and destroy repeatedly

\subsection{Advanced Use}

Thus far, we have focused on functions in \pkg{Rtesseract} which allow
for accessing and manipulating the results of running the OCR engine
on an image. In complex cases, it might be desirable to manipulate the
behavior of the OCR engine itself rather than merely the output. For
these purposes, the \pkg{Rtesseract} packages exposes full access to
the \code{TesseractBaseAPI}, which allows fine-tuning of the OCR for
specific cases.

To continue the example above, on inspection of the results of the OCR
there are some domain-specific terms that are not being recognized
correctly. While it might be possible to correct these in
post-processing, it is preferable to tweak the settings of the OCR
engine to aid the correct recognition in the processing stage. The
above document includes the two terms that are consistently
mis-recognized; {\it{``Ae. aegypti''}} (a scientific name) and ``São
Paulo'' (a non-English place name). \code{Tesseract} allows
user-specified words to be added to the dictionary of correct matches
through a ``user-words'' file. \pkg{Rtesseract} allows you to specify
this file, which will then be used by the OCR engine to resolve
ambiguities: 

<<new>>=
# Create a user-words file for English
writeLines(c("aegypti", "São"), "eng.user-words")

# Create a new API for comparison
api2 = tesseract(f, pageSegMode="psm_auto", engineMode = 2,
                 datapath = path.expand("~/DSI/tessdata"),
                 opts = list(user_words_file = path.expand("~/DSI/Rtesseract/inst/Paper/")))

#Fixed error in OCR engine rather than post-process results
GetText(api2, "textline")[34]
GetText(api, "textline")[34]

@

Many customizable variables which allow fine control of the OCR engine
are accessible through R via the \pkg{Rtesseract} package, including
pageSegMode, pageOrientation, language, white- and black-list
characters, custom user-added patterns and words, alternative OCR
engines, etc. Full documentation of user-adjustable variables is
available at
\url{https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc}.
As seen above, by creating persistent TesseractBaseAPI objects, two or
more APIs can be created with differing customized variables and their
results can be inspected without the need to constantly recreate and
then destroy the TesseractBaseAPI.

%% Expand
%\begin{figure}[htbp]
%<<a, fig=TRUE, warning=FALSE, echo=FALSE>>=
%f = system.file("images", "1990_p44.png", package = "Rtesseract")
%ts = tesseract(f, pageSegMode = "psm_auto", ,
%              opts = list(tessedit_char_whitelist = paste(LETTERS, 0:9, " .-",
%                                                          collapse = "")))
%Recognize(ts)
%
%bb = GetBoxes(ts)
%
%quantile(bb[,"right"] - bb[,"left"], probs = seq(0,1, 0.1)) 
%
%i = bb[,"right"] - bb[,"left"] > 500
%bb[i,]
%m = plot(ts, fillBoxes = TRUE)
%rect(m[i,"left"],m[i,"bottom"],m[i,"right"],m[i,"top"], col = "red", border = NA)
%abline(v = Rtesseract:::findColumns(api = ts, ncols = 8, side = "left"))
%
%@
%\caption{An example of using the spatial information from the bounding
%  boxes to find elements on the recognized image, including lines
%  which separate parts of a table, and the location of columns.}
%\label{fig:spatial}
%\end{figure}
%
\subsection{Meta data}

Lastly, in addition to the base functions, meta data about the OCR
engine and the input image can be retrieved using \pkg{Rtesseract}
using a collection of functions. The current version of Tesseract can
be returned by \code{tesseractVersion}, while the capabilities for
reading various image formats via leptonica is provided by
\code{leptonicaImageFormates}. Information about the source image are
also accessible through R using the \code{GetInputName},
\code{getImageInfo},\code{GetImageDims}, and
\code{GetSourceResolution} functions.

The current settings for the tesseract OCR engine are returned by
\code{PrintVariables} (returns \Sexpr{length(PrintVariables())}
variables at the time of writing). These variables can be adjusted via
a call to \code{SetVariables}. Additionally, configurations of these
variable options can be read in from a file with the function
\code{ReadConfigFile}, allowing easy saving of configurations for
sharing between computers. By default, \pkg{Rtesseract} searches the
/usr/bin/local directory for installed trained language files, but
this can be overridden. The current location where the API is
searching for language data is returned by \code{GetDataPath}.

% Looking at and changing options
<<>>=
v = PrintVariables()
v[grep("tessedit_char", names(v))]
@ 

\section{Installation}

In order to use \pkg{Rtesseract}, users must first have Tesseract and
its dependency, Leptonica, installed. Tesseract is available from
\url{https://github.com/tesseract-ocr/} and Leptonica from
\url{https://github.com/DanBloomberg/leptonica}. Additionally, users
must have a trained language data set installed. Currently, there are
pre-trained data sets for 140+ languages available from
\url{https://github.com/tesseract-ocr}. Users are also able to provide
their own trained data. For more information about training Tesseract,
please see
\url{https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract}. \pkg{Rtesseract}
includes some functions that assist with training, including
\code{ReadBoxFile()}. Finally, \pkg{Rtesseract} can be installed from
source at \url{https://github.com/duncantl/Rtesseract}.%%Expand

\section{Advantages}

\pkg{Rtesseract} provides both easy access to basic OCR functionality
for simple use-cases as well as access to low-level control parameters
for more advanced uses. By allowing recovery of additional information
generated by Tesseract, such as confidence levels and bounding boxes,
\pkg{Rtesseract} supports novel applications of inputting data from
images into R (e.g., spatial analysis of text). Leveraging free,
open-source software allows full integration of the full work-flow of
text from images into R. \pkg{Rtesseract} works with both the current
stable release (3.05) and the alpha release (4.00alpha).

\bibliography{Rtesseract.bib}
