% !TeX root = RJwrapper.tex

\title{Rtesseract: A package for Optical Character Recognition (OCR)
  from R}

\author{by Matthew B. Espe and Duncan Temple Lang}

\maketitle

\begin{abstract}

  % Work on this after the rest is more or less where we want it
  We describe \pkg{Rtesseract}, and R package that provides access
to Tesseract, an Open Source C++ library for Optical Character Recognition
(OCR), from within R. 
At its simplest, \pkg{Rtesseract} allows an R user to recover of text from an image
as lines, words or individual characters.
We can also obtain the location of these text elements,
possible alternatives and the predictive ``confidence'' for each.
These are often necessary for interpreting the text, e.g.,
for multicolumn layout, or tables.
The package provides access to much of the  TesseractBaseAPI, allowing full customization of OCR behavior
and also exporting the results in various formats (e.g. PDF)
and also visualizing them within R itself.
\end{abstract}

\section{Introduction}\label{intro}

<<setup, echo=FALSE, message=FALSE, warning=FALSE>>=
library(Rtesseract)
library(knitr)

# Globally set output to be limited to 4 lines
knit_theme$set("print")
opts_chunk$set(out.lines = 4)
opts_chunk$set(highlight = FALSE, background = "white", prompt = TRUE,
               comment = '')


# # the default output hook
# # From https://github.com/yihui/knitr-examples
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
    if (!is.null(n <- options$out.lines)) {
        x = unlist(stringr::str_split(x, "\n"))
        if (length(x) > n) {
            # truncate the output
            x = c(head(x, n), "....\n")
        }
        x = paste(x, collapse = "\n")  # paste first n lines together
    }
    hook_output(x, options)
})

              

@ 
There has been an enormous increase in the amount of text data that we
work with from social media, reports, scholarly articles, job applications.
These often come as plain text or structured documents such as word-processing files, 
HTML, PDF. However, there are many documents of interest that are only available as scanned images,
e.g., old books, newspapers.
Optical Character Recognition (OCR) is a technique to infer characters, words or lines of text from an image,
thereby making it accessible for data analysis.
There are many OCR software tools available, e.g., Adobe Acrobat, PDFPen Pro, ABBY.
These typically only output the results to a file. End-users are not often
given access fine scale controls, or able customize the trained
behavior of the tool.  Importantly, the results are just the text.

In response to our needs,  we developed an interface to the open source tesseract library.
Importantly, this interface provides us 1) a simple high-level 
function to extract the text from one or more images,
2) the ability to also obtain important auxiliary data,
e.g., the confidence in each prediction, the location within the image,
and 3) customization of how the OCR is done.
The results are accessible directly within R as
text and/or a data frame of locations and confidences.


This approach tightly integrates pre- and post-processing steps with the actual OCR. For example, we
can focus on a sub-region of the image, or enhance the image with some computer vision techniques
before performing the character recognition.  We can specify a domain-specific vocabulary, or
identify unconventional fonts.  The tight integration simplifies workflows that rely on invoking
stand-alone applications typically meant for human interactive use.  Also, the metadata about the
resulting text aids subsequent analyses. For example, the layout of the text into blocks, the
presence of elements such as lines or other dividers, or even the relative size of the text can all
be used to make sense of the resulting text. Diagnostic pieces of information such as the confidence
in the matches, alternative matches, etc., can be essential to improving OCR accuracy. If the OCR
tool only returns the text results, OCR's usefulness is limited to cases where the problem is either
simple or well-covered by the default setup.


\begin{comment}
Data are rarely in a form amenable to data analysis. At the extreme,
data may be inaccessible in their current form, for example in images
or scans of documents or other records. Optical Character Recognition
(OCR) is a technique to infer strings or characters from an image, thereby
converting images into a format that can be directly manipulated
by a computer program. Typically OCR is used to convert a scanned
image of a text to a digital copy, which can be of the form of a
simple text file , a structured text file (e.g., XML or HOCR), a
``search-able'' PDF document, etc.. While there are many pieces of
software with the capability to convert images of data into
computer-usable formats (e.g., Adobe Acrobat, PDFPen Pro, ABBY, etc.),
these typically only output the result file. End-users are not often
given access fine scale controls or intermedate outputs, and are not
often able customize the trained behavior of the tool.

There are a few issues with this arrangement. 
\end{comment}

% In contrast, the \pkg{Rtesseract} package has been developed to
% provide both 

% % not sure where to put this

% In addition to extracting numeric data, OCR
% allows the extraction of text, expanding corpus available for the
% increasingly powerful capacity to analyze the contents of text
% quantitatively (e.g., Natural Language Processing and Digital
% Humanities). Lastly, these tools can be used to efficiently (compared
% to human transcription) enter text from a simple image into a computer
% representation.  Here, we describe a low-level and highly expandible
% tool to extract text and data from images into R, an environment for
% statistical computing.

Here, we describe the \pkg{Rtesseract} package, which addresses many
of the above concerns. \pkg{Rtesseract} provides an
interface to Tesseract, a fully capable, highly flexible, and open
source OCR engine. The design philosophy of the \pkg{Rtesseract}
package is to provide convenience wrappers for the OCR engine in R,
allowing ``out-of-the-box'' OCR capability while preserving access to
the fine-scale controls for more advanced use cases. Development of
\pkg{Rtesseract} began in Apr. 2015, and while there are other
packages which provide wrappers of the Tesseract command line
executable \citep{Hagmann2014}, or API \citep{ooms2016}, the
\pkg{Rtesseract} package allows additional functionality and finer
control by giving full access to the TesseractBaseAPI from within
R. \pkg{Rtesseract} supports both the current release (v3.05.01) and
development versions (v4.00.alpha) of Tesseract.

% Might need to remove this? is it really needed?
Tesseract development began at Hewlett
Packard Laboratories Bristol and Hewlett Packard Co between 1985 to
1994 \citep{Smith2007}. It was entered into 1995 UNLV Annual Test of
OCR Accuracy, where it scored well against commercial products. Little
additional development occurred between 1995 and when the code base
was released for Open Source in 2005. Since 2005, Tesseract has been
maintained by Google and open-source developers. Tesseract depends on
Leptonica, an open source program for image manipulation, processing,
and analysis. Recent developments to Tesseract include the integration
of LSTM Deep Learning networks (versions >= 4.0) for increased speed
and accuracy. An advantage of Tesseract over many commercial OCR
products is that Tesseract allows user-training to custom fonts and
languages and user-access to OCR engine control parameters, which
allows users to custom tailor the OCR engine's behavior to specific
applications (e.g., unusual fonts or languages, domain specific
vocabulary, etc.).


\section{Package Motivation}\label{desc}

For many simple problems, merely extracting text from an image in a
reliable manner is sufficient. \pkg{Rtesseract} provides simple
interfaces that allow users to provide the path to an image in a
supported format (tiff, JPEG, and png on most systems), and OCR will be
run on the image using the default settings. For example, say we had
an image of the first page of a scientific publication:

% Probably want to show this as otherwise, we are using a variable people don't see.
% So let's define it in the first place we use it.
<<echo=FALSE>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
@ 

\begin{figure}[h]
\includegraphics[width=\textwidth]{\Sexpr{f}}
\caption{An example image of a scientific paper.}
\end{figure}

\subsection{Base Functions}

For the simplest task of retrieving the text contents of the image,
we use the high-level function
\code{GetText}. 
We pass it the path to a file containing the image
%this function will
%create a \code{TesseractBaseAPI} object, run the OCR engine, destroy
%the \code{TesseractBaseAPI} and then return the text. 
By default, it returns the words it finds in the image in the order they appear.
<<>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
GetText(f)
@ 
However, rather than words, we sometimes want individual characters, text-lines
or entire paragraphs. We can specify this via the \code{level} parameter.
<<>>=
GetText(f, level = "textline")

@ 
\code{GetText} therefore provides the functionality of most basic OCR applications. 


However, merely retrieving text can be of limited usefulness. Users
might wish to know the location of the match, how confident the OCR
engine is in each match, and what alternatives exist for the returned
match. For these tasks, \pkg{Rtesseract} includes three other
high-level functions: \code{GetConfidences}, \code{GetAlternatives},
and \code{GetBoxes}. Similar to \code{GetText}, these
functions can take the path of the image file 
and the optional \code{level} argument.

If we call \code{GetText} followed by another
to, e.g., \code{GetAlternatives} for the same file,
we would repeat the OCR twice on that same file.
Since this is reasonably computationally intensive, we want to perform
the OCR once and then query each of the results we want, i.e.,
the text, the confidences, the alternatives, \ldots.

%XXX So I would show the code calling tesseract() and then GetText(), GetBoxes(), GetConfidences() right now
% Then discuss why it is useful.

For these cases where the user is interested in multiple pieces of
information from a single file, 
we use the \code{tesseract} function to create an instance of the OCR
engine (an object of class \code{TesseractBaseAPI} in R). 
We specify the path to the file and any other options controlling how the OCR will be performed.
We then pass this to each of the four high level functions rather than the file name. 
% It is not lazy evaluation.
By default, the call to \code{tesseract} doesn't perform the OCR immediately.
Instead, it is only done when we request any results, e.g., calling
any of the four functions above, or explicitly calling the \code{Recognize}
function with the .


For example, say we wanted to OCR the previous image, but also were
interested if the shadow on edges of the image affected the OCR
performance from left to right. Since the confidences for each match
are available to us, we can easily explore this relationship
statistically and/or visually.

% this is a bit contrived since I added shadow to the image. We could also take
% a look at the confidences at the word or character level to see
% which are causing the most issues.

%XXX Need to explain pageSegMode.  Different from level.

<<echo = FALSE>>=
api = tesseract(f, pageSegMode = "psm_auto")

# See if the shadow is affecting the OCR
bb = GetBoxes(api, level = "symbol")
@



<<>>=
# Group words by the center of their bounding box left to right
gg = cut(rowMeans(bb[,c(1,3)]), breaks = seq(0, max(bb[,3]), length.out = 7))
tapply(bb[,"confidence"], gg, summary)
@

\begin{figure}[h]
<<fig=TRUE, echo = FALSE>>=

scatter.smooth(bb[,5] ~ rowMeans(bb[,c(1,3)]),
     xlab = "Position of character bounding box on page",
     ylab = "Confidence (higher is more confident)",
     xaxt = "n",
     pch = 16, col = rgb(0,0,0,0.25))
axis(1, at = c(500,2000,3500), labels = c("left", "center", "right"))

@ 
\caption{An example how visualizing the confidences from the OCR
  allows investigation of how location on the page influences
  the results of the OCR engine.}
\end{figure}

Furthermore, \pkg{Rtesseract} includes a default plotting function for
OCR output for users to visually inspecting the results. We have found
these plots, which by default include the bounding boxes colored by
relative confidence overlaid over the original image (see
Fig. \ref{fig:rtess_plot} for an example), helpful in diagnosing OCR
behavior and inaccuracies. Plotting the results is especially helpful
when adjusting the OCR configuration settings (discussed below under
``Advanced Use'').

Similarly, by allowing access to information regarding the bounding
boxes, \pkg{Rtesseract} enables users to use location or size specific
information manipulate the results of the OCR. For example,
identifying the title in the above image from plain text results would
involve using context-based heuristics, but the task is far simpler
with access to information about the text size:

\begin{figure}[h]
<<echo = FALSE>>=
plot(api, fillBoxes = TRUE)
@
\caption{\pkg{Rtesseract}'s plotting function allows the user to
  overlay the original image with the bounding boxes and associated
  confidences.}
\label{fig:rtess_plot}
\end{figure}

<<>>=
# To locate the title, first get the text-line level bounding boxes
bb = GetBoxes(api, level = "textline")

# Find the tallest box for a single text line
rownames(bb)[which.max(bb[,4] - bb[,2])]

@ 

We have used the location of the bounding boxes to identify and
reconstruct text arranged in columns, separating by unrelated elements
(e.g., newspaper content), or even to reconstruct complex tabular
content. In our use, we have found using the bounding boxes preferable
to attempting to simulate the layout of the page by padding the text
with spaces (e.g., the ``layout'' output of many other OCR
engines).

Using these bounding boxes as guides, we are able to adjust the OCRed
area without leaving R. Continuing the example, say we were primarily
interested in the abstract. 

% BB are better than padding results with spaces to simulate
% the layout

% New Example - start with just getting text
% Look for title - need bounding boxes
% Then by lines - illustrates the need to build the api object
% rather than call and destroy repeatedly

\subsection{Advanced Use}

Thus far, we have focused on functions in \pkg{Rtesseract} which allow
for accessing and manipulating the results of running the OCR engine
on an image. In complex cases, it might be desirable to manipulate the
behavior of the OCR engine itself rather than merely the output. For
these purposes, the \pkg{Rtesseract} packages exposes full access to
the \code{TesseractBaseAPI}, which allows fine-tuning of the OCR for
specific cases.

To continue the example above, on inspection of the results of the OCR
there are some domain-specific terms that are not being recognized
correctly. While it might be possible to correct these in
post-processing, it is preferable to tweak the settings of the OCR
engine to aid the correct recognition in the processing stage. The
above document includes the two terms that are consistently
mis-recognized; {\it{``Ae. aegypti''}} (a scientific name) and ``São
Paulo'' (a non-English place name). \code{Tesseract} allows
user-specified words to be added to the dictionary of correct matches
through a ``user-words'' file. \pkg{Rtesseract} allows you to specify
this file, which will then be used by the OCR engine to resolve
ambiguities: 

<<new>>=
# Create a user-words file for English
writeLines(c("aegypti", "São"), "eng.user-words")

# Create a new API for comparison
api2 = tesseract(f, pageSegMode="psm_auto", engineMode = 2,
                 datapath = path.expand("~/DSI/tessdata"),
                 opts = list(user_words_file = path.expand("~/DSI/Rtesseract/inst/Paper/")))

#Fixed error in OCR engine rather than post-process results
GetText(api2, "textline")[34]
GetText(api, "textline")[34]

@

Many customizable variables which allow fine control of the OCR engine
are accessible through R via the \pkg{Rtesseract} package, including
pageSegMode, pageOrientation, language, white- and black-list
characters, custom user-added patterns and words, alternative OCR
engines, etc. Full documentation of user-adjustable variables is
available at
\url{https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc}.
As seen above, by creating persistent TesseractBaseAPI objects, two or
more APIs can be created with differing customized variables and their
results can be inspected without the need to constantly recreate and
then destroy the TesseractBaseAPI.

%% Expand
%\begin{figure}[htbp]
%<<a, fig=TRUE, warning=FALSE, echo=FALSE>>=
%f = system.file("images", "1990_p44.png", package = "Rtesseract")
%ts = tesseract(f, pageSegMode = "psm_auto", ,
%              opts = list(tessedit_char_whitelist = paste(LETTERS, 0:9, " .-",
%                                                          collapse = "")))
%Recognize(ts)
%
%bb = GetBoxes(ts)
%
%quantile(bb[,"right"] - bb[,"left"], probs = seq(0,1, 0.1)) 
%
%i = bb[,"right"] - bb[,"left"] > 500
%bb[i,]
%m = plot(ts, fillBoxes = TRUE)
%rect(m[i,"left"],m[i,"bottom"],m[i,"right"],m[i,"top"], col = "red", border = NA)
%abline(v = Rtesseract:::findColumns(api = ts, ncols = 8, side = "left"))
%
%@
%\caption{An example of using the spatial information from the bounding
%  boxes to find elements on the recognized image, including lines
%  which separate parts of a table, and the location of columns.}
%\label{fig:spatial}
%\end{figure}
%
\subsection{Meta data}

Lastly, in addition to the base functions, meta data about the OCR
engine and the input image can be retrieved using \pkg{Rtesseract}
using a collection of functions. The current version of Tesseract can
be returned by \code{tesseractVersion}, while the capabilities for
reading various image formats via leptonica is provided by
\code{leptonicaImageFormates}. Information about the source image are
also accessible through R using the \code{GetInputName},
\code{getImageInfo},\code{GetImageDims}, and
\code{GetSourceResolution} functions.

The current settings for the tesseract OCR engine are returned by
\code{PrintVariables} (returns \Sexpr{length(PrintVariables())}
variables at the time of writing). These variables can be adjusted via
a call to \code{SetVariables}. Additionally, configurations of these
variable options can be read in from a file with the function
\code{ReadConfigFile}, allowing easy saving of configurations for
sharing between computers. By default, \pkg{Rtesseract} searches the
/usr/bin/local directory for installed trained language files, but
this can be overridden. The current location where the API is
searching for language data is returned by \code{GetDataPath}.

% Looking at and changing options
<<>>=
v = PrintVariables()
v[grep("tessedit_char", names(v))]
@ 

\section{Installation}

In order to use \pkg{Rtesseract}, users must first have Tesseract and
its dependency, Leptonica, installed. Tesseract is available from
\url{https://github.com/tesseract-ocr/} and Leptonica from
\url{https://github.com/DanBloomberg/leptonica}. Pre-compiled binaries
are available for most platforms for the current stable version
(v3.05). As previously mentioned \pkg{Rtesseract} also works with the
development version of Tesseract (4.00alpha) currently available from
\url{https://github.com/tesseract-ocr/tesseract/releases}. However, to
build Tesseract from source requires many additional pieces of
software, including leptonica v1.74+, automake, libtool, pkg-config,
aclocal, autoheader, and
autoconf-archive. Additionally, to use Tesseract users must have a
trained language data set installed. Currently, there are pre-trained
data sets for 140+ languages available from
\url{https://github.com/tesseract-ocr}. Users are also able to provide
their own trained data. For more information about training Tesseract,
please see
\url{https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract}. \pkg{Rtesseract}
includes some functions that assist with training, including
\code{ReadBoxFile()}. Finally, \pkg{Rtesseract} can be installed from
source at \url{https://github.com/duncantl/Rtesseract}.

\section{Advantages}

\pkg{Rtesseract} provides both easy access to basic OCR functionality
for simple use-cases as well as access to low-level control parameters
for more advanced uses. By allowing recovery of additional information
generated by Tesseract, such as confidence levels and bounding boxes,
\pkg{Rtesseract} supports novel applications of inputting data from
images into R (e.g., spatial analysis of text). Leveraging free,
open-source software allows full integration of the full work-flow of
text from images into R. \pkg{Rtesseract} works with both the current
stable release (3.05) and the alpha release (4.00alpha).

\bibliography{Rtesseract.bib}
