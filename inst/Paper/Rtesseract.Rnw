% !TeX root = RJwrapper.tex


% Things we should add or make certain are there 
%
% + Examples showing setting some of the options and why they matter
%   e.g. language, white list
% + Querying current options/configuration settings.
%
% + Getting the dimension of the image 
%    See  getImage.R 
% + Limiting to a particular  subregion.
%     See ./setRectangle.R and the SetRectangle example.
%
% + Setting an image after processing it in R first. Have to check this works. 
%     SetImage_raw
%

\title{Rtesseract: A package for Optical Character Recognition (OCR)
  from R}

\author{by Matthew B. Espe and Duncan Temple Lang}

\maketitle

\begin{abstract}

We created the \pkg{Rtesseract} package to support working with text data
present in images. \pkg{Rtesseract} is an R package that provides
access to Tesseract, an Open Source C++ library for Optical Character
Recognition (OCR), from within R.  At its simplest, \pkg{Rtesseract}
allows an R user to recover of text from an image as lines, words or
individual characters.  We can also obtain the location of these text
elements, possible alternatives and the predictive ``confidence'' for
each.  These are often necessary for interpreting the text, e.g., for
multicolumn layout, or tables.  The package provides access to much of
the \code{TesseractBaseAPI}, allowing full customization of OCR
behavior and also exporting the results in various formats (e.g. PDF)
and also visualizing them within R itself. With the \pkg{Rtesseract}
package, users are able to create a fully programmatic workflow to
extract text data into R for subsequent analysis.

\end{abstract}

\section{Introduction}\label{intro}

<<setup, echo=FALSE, message=FALSE, warning=FALSE>>=
library(Rtesseract)
library(knitr)

# Globally set output to be limited to 4 lines
knit_theme$set("print")
opts_chunk$set(out.lines = 4)
opts_chunk$set(highlight = FALSE, background = "white", prompt = TRUE,
               comment = '')


# # the default output hook
# # From https://github.com/yihui/knitr-examples
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
    if (!is.null(n <- options$out.lines)) {
        x = unlist(stringr::str_split(x, "\n"))
        if (length(x) > n) {
            # truncate the output
            x = c(head(x, n), "....\n")
        }
        x = paste(x, collapse = "\n")  # paste first n lines together
    }
    hook_output(x, options)
})

          
@ 

There has been an enormous increase in the amount of text data that we
work with from social media, reports, scholarly articles, job
applications, etc. These often come as plain text or structured documents
such as word-processing files, HTML, PDF. However, there are many
documents of interest that are only available as scanned or
photographic images (e.g., old books, newspapers). Optical Character
Recognition (OCR) is a technique to infer characters, words or lines
of text from an image, thereby making it accessible for data
analysis. There are many OCR software tools available (e.g., Adobe
Acrobat, PDFPen Pro, ABBY), though these typically only output the
results to a file. End-users are not often given access fine scale
controls, or are able customize the trained behavior of the
tool. Importantly, the results often contain just the text.

In response to our needs, we developed the \pkg{Rtesseract} package,
an interface to the open source OCR library Tesseract. Tesseract was
created 1985, was released for open source in 2005, and has since been
actively maintained and developed by the open source community
(including developers at Google). Recent innovations in Tesseract
include the integration of LSTM Deep Learning networks (versions >=
4.0) for increased speed and accuracy. By interfacing with Tesseract,
the \pkg{Rtesseract} package provides us 1) a simple high-level
function to extract the text from one or more images, 2) the ability
to also obtain important auxiliary data (e.g., the confidence in each
prediction, the location within the image), and 3) customization of
how the OCR is done. Additionally, the results are accessible directly
within R as text and/or a data frame of locations and confidences.

This approach using \pkg{Rtesseract} tightly integrates pre- and
post-processing steps with the actual OCR. For example, we can focus
on a sub-region of the image, or enhance the image with some computer
vision techniques before performing the character recognition. We can
specify a domain-specific vocabulary, or identify unconventional
fonts. This tight integration simplifies workflows that otherwise rely
on invoking stand-alone applications typically meant for human
interactive use. Furthermore, metadata about the resulting text can
aid and inform subsequent analyses. For example, the layout of the text into blocks,
the presence of elements such as lines or other dividers, or even the
relative size of the text can all be used to make sense of the
resulting text. Diagnostic pieces of information such as the
confidence in the matches, alternative matches, etc., can be essential
to improving OCR accuracy. If the OCR tool only returns the text
results, OCR's usefulness is limited to cases where the problem is
either simple or well-covered by the default setup.

Since we initially created \pkg{Rtesseract} in April 2015, two other R
packages interfacing to Tesseract have been released.  The \pkg{ocR}
package~\citep{Hagmann2014} provides an interface to calling the
Tesseract command line executible.  Using the \pkg{ocR} package, the
user specifies the image file and the results that Tesseract writes to
a file are read into R. The \pkg{tesseract} package~\citep{ooms2016}
takes a similar approach to \pkg{Rtesseract} package by interfacing to
the C++ library. However, by design, it provides only functionality to
get the text results from the OCR process. \pkg{Rtesseract}, from its
initial implementation, provides access to a most of the functionality
in te Tesseract API and provides fine-grain control from R to the
different steps in the OCR process. \pkg{Rtesseract} supports both the
current release (v3.05.01) and development versions (v4.00.alpha) of
Tesseract.

\section{Package Description}\label{desc}

For many simple problems, merely extracting text from an image in a
reliable manner is sufficient. \pkg{Rtesseract} provides simple
interfaces that allow users to provide the path to an image in a
supported format (tiff, JPEG, and png on most systems), and OCR will be
run on the image using the default settings. For example, say we had
an image of the first page of a scientific publication (Fig. \ref{fig:base}).

<<echo = FALSE>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
@ 

\begin{figure}[h]
\includegraphics[width=\textwidth]{\Sexpr{f}}
\label{fig:base}
\caption{An example image of a scientific paper which contains text we
  would like to analyze.}
\end{figure}

\subsection{Base Functions}

For the simplest task of retrieving the text contents of the image, we
use the high-level function \code{GetText}.  We pass it the path to a
file containing the image.  By default, it returns the words it finds
in the image in the order they appear.

<<>>=
f = system.file("images", "Biological_YF_Risk-0_02.png", package = "Rtesseract")
GetText(f)
@

However, rather than words, we sometimes want the results arranged as
individual characters, text-lines or entire paragraphs. We can specify
this via the \code{level} parameter.

<<>>=
GetText(f, level = "textline")

@ 
\code{GetText} therefore provides the functionality of most basic OCR applications. 

However, merely retrieving text can be of limited usefulness. Users
might wish to know the location of the match, how confident the OCR
engine is in each match, and what alternatives exist for the returned
match. For these tasks, \pkg{Rtesseract} includes three other
high-level functions: \code{GetConfidences}, \code{GetAlternatives},
and \code{GetBoxes}. Similar to \code{GetText}, these functions can
take the path of the image file and the optional \code{level}
argument.

If we call \code{GetText} followed by another to, e.g.,
\code{GetAlternatives} for the same file, we would repeat the OCR
twice on that same file. Since this is reasonably computationally
intensive, we want to perform the OCR once and then query each of the
results we want (i.e., the text, the confidences, the alternatives,
\ldots).

<<>>=
api = tesseract(f)
GetText(api)
GetBoxes(api)
GetConfidences(api)
@ 

For these cases where the user is interested in multiple pieces of
information from a single file, we use the \code{tesseract} function
to create an instance of the OCR engine (an object of class
\code{TesseractBaseAPI} in R). We specify the path to the file and any
other options controlling how the OCR will be performed. We then pass
this to each of the four high level functions rather than the file
name. By default, the call to \code{tesseract} doesn't perform the OCR
immediately.  Instead, it is only done when we request any results,
e.g., calling any of the four functions above, or explicitly calling
the \code{Recognize} function with the \code{TesseractBaseAPI} object
as an argument.

For example, say we wanted to OCR the previous image, but also were
interested if the shadow on edges of the image affected the OCR
performance from left to right. Since the confidences for each match
are available to us, we can easily explore this relationship
statistically and/or visually.

% this is a bit contrived since I added shadow to the image. We could also take
% a look at the confidences at the word or character level to see
% which are causing the most issues.

%XXX Need to explain pageSegMode.  Different from level. - Moved to later

<<echo = FALSE>>=
api = tesseract(f)

# See if the shadow is affecting the OCR
bb = GetBoxes(api, level = "symbol")
@

We can get the locations and associated confidences for each
individual symbol recognized by Tesseract. Then these can be
manipulated in R to explore the relationships between location and
confidence (See Fig. \ref{conf_by_loc} for an example).

<<>>=
# Group words by the center of their bounding box left to right
gg = cut(rowMeans(bb[,c(1,3)]), breaks = seq(0, max(bb[,3]), length.out = 7))
tapply(bb[,"confidence"], gg, summary)
@

\begin{figure}[h]
<<fig=TRUE, echo = FALSE>>=

scatter.smooth(bb[,5] ~ rowMeans(bb[,c(1,3)]),
     xlab = "Position of character bounding box on page",
     ylab = "Confidence (higher is more confident)",
     xaxt = "n",
     pch = 16, col = rgb(0,0,0,0.25))
axis(1, at = c(500,2000,3500), labels = c("left", "center", "right"))

@ 
\caption{An example how visualizing the confidences from the OCR
  allows investigation of how location on the page influences
  the results of the OCR engine.}
\label{fig:conf_by_loc}
\end{figure}

Furthermore, \pkg{Rtesseract} includes a default plotting function for
OCR output for users to visually inspecting the results. We have found
these plots, which by default include the bounding boxes colored (and
optionally filled) by relative confidence overlaid over the original
image (see Fig. \ref{fig:rtess_plot} for an example), helpful in
diagnosing OCR behavior and inaccuracies. Plotting the results is
especially helpful when adjusting the OCR configuration settings
(discussed below under ``Advanced Use'').

\begin{figure}[h]
<<echo = FALSE>>=
plot(api, fillBoxes = TRUE)
@
\caption{\pkg{Rtesseract}'s plotting function allows the user to
  overlay the original image with the bounding boxes and associated
  confidences.}
\label{fig:rtess_plot}
\end{figure}

Similarly, by allowing access to information regarding the bounding
boxes, \pkg{Rtesseract} enables users to use location or size specific
information manipulate the results of the OCR. For example,
identifying the title in the above image from plain text results would
involve using context-based heuristics, but the task is far simpler
with access to information about the text size:

<<>>=
# To locate the title, first get the text-line level bounding boxes
bb = GetBoxes(api, level = "textline")

# Find the tallest box for a single text line
rownames(bb)[which.max(bb[,4] - bb[,2])]

@ 

We have used the location of the bounding boxes to identify and
reconstruct text arranged in columns, separating by unrelated elements
(e.g., newspaper content), or even to reconstruct complex tabular
content. In our use, we have found using the bounding boxes preferable
to attempting to simulate the layout of the page by padding the text
with spaces (e.g., the ``layout'' output of many other OCR engines).

\section{Advanced Use}

Thus far, we have focused on functions in \pkg{Rtesseract} which allow
accessing and manipulating the results of running the OCR engine on an
image. In complex cases, you might want to manipulate the behavior of
the OCR engine itself rather than merely the output. For these
purposes, the \pkg{Rtesseract} packages exposes full access to the
\code{TesseractBaseAPI}, which allows fine-tuning of the OCR engine
for specific cases.

\subsection{Page Segmentation Mode and OCR Engine}

Two variables, \code{pageSegMode} and \code{engineMode}, deserve
special mention because these two can have large impact on the results of the
OCR. The first, the Page Segmentation Mode, adjusts how Tesseract
recognizes lines of text in the image. By adjusting Page Segmentation
Mode, the user can specify if the text is present in many different
configurations, including (but not limited to) single block, sparce
text, vertical or circular arrangement, etc. The \pkg{Rtesseract}
package preserves the defaults in the \code{TesseractAPI} and assumes
the input is a single block of text (\code{PSM\_SINGLE\_BLOCK}) by
default, though in our experience OCR can be significantly improved
with changing the Page Segmentation Mode. We have found for most
problems \code{PSM\_AUTO}, which attempts to detect the correct page
segmentation automatically, is a good default, though any of the currently
\Sexpr{length(grep("^PSM_",ls('package:Rtesseract')))} available Page
Segmentation modes might be best for different applications (curiously,
\code{PSM\_AUTO} is the default for the tesseract command line tool
but not for the API). Page Segmentation Mode can be set either in the
call to \code{tesseract}, in the \code{...}  arguments for any of the
high-level functions (e.g., \code{GetText(f, pageSegMode =
"PSM\_AUTO")}), or by using \code{SetPageSegMode} on an existing
\code{TesseractBaseAPI} object.

The second of these variables is the Tesseract Engine Mode, which
determines what OCR engine is used to recognize text. By default,
\pkg{Rtesseract} uses Tesseract only. Depending on installed version
of Tesseract, other OCR engines can be used individually or in
combination with Tesseract (Cube for Tesseract versions 3.04+, LSTM for
Tesseract versions 4.00+). Although the use of these in combination
with Tesseract can increase accuracy, their use can add significant
computational load (between 6--10x) and require appropriately trained
language files, so they are not used by default by \pkg{Rtesseract}'s
OCR functions. 

\subsection{Other Variables}

There are a plethera of variables that can be adjusted, so for space
considerations we will highlight the ones we have found the most
useful in our work. To continue the example above, on inspection of
the results of the OCR there are some domain-specific terms that are
not being recognized correctly. While it might be possible to correct
these in post-processing, it is preferable to tweak the settings of
the OCR engine to alow the correct recognition in the processing
stage. The above document includes the two terms that are consistently
mis-recognized; {\it{``Ae. aegypti''}} (a scientific name) and ``São
Paulo'' (a non-English place name). \code{Tesseract} allows
user-specified words to be added to the dictionary of correct matches
through a ``user-words'' file. \pkg{Rtesseract} allows you to specify
this file, which will then be used by the OCR engine to resolve
ambiguities:

<<new>>=
# Create a user-words file for English
writeLines(c("aegypti", "São"), "eng.user-words")

# Create a new API for comparison
api2 = tesseract(f, pageSegMode="psm_auto", 
                 opts = list(user_words_file = "eng.user-words"))

# path.expand("~/DSI/Rtesseract/inst/Paper/")))

#Fixed error in OCR engine rather than post-process results
GetText(api2, "textline")[34]
GetText(api, "textline")[34]

@

Extending this idea, we can explore which characters have the lowest
confidence and/or occurence in the text.

<<>>=
symbolBB = GetBoxes(api, level = "symbol")
symbolConf = sort(tapply(symbolBB[,"confidence"], row.names(symbolBB), median))
# Lowest eight 
symbolConf[1:8]
@

We can visually inspect these low-confidence characters to verify that
they are correct using the \code{plotSubImage} function for a single
bounding box, or the \code{plotSubsets} function to create a panel
plot of multiple bounding boxes (Fig. \ref{fig:subsets}.

\begin{figure}
<<fig = TRUE>>=
idx = which(symbolBB[,"confidence"] < 70)

plotSubsets(symbolBB[idx,], img = png::readPNG(f))
@
\caption{An example of the \code{plotSubsets} function, which creates panel plots of
  individual subsets of the image along with the associated OCR result
  and confidence. In this example, the ``ã'' character is oft
  mis-recognized.}
\label{fig:subsets}
\end{figure}

Continuing the example, say we were primarily interested in the
abstract. Using the bounding boxes or other coordinates as guides, we
are able to adjust the OCRed area without leaving R. Typically, to do
this would involve partitioning the image into subsets using an image
editing tool (e.g., Gimp, Darktable, Photoshop), and then running the
OCR on each of these subset images. This process involves leaving R
and involves steps that may be difficult to replicate. However,
\pkg{Rtesseract} allows the user to specify a rectangle of interest
using the \code{SetRectangle} function. This function takes a
\code{TesseractBaseAPI} object and the left, top, width and height of
the sub-area as additional arguments (the dimensions of the full input
image can be found with \code{GetImageDims}). Once set, the next call to the
\code{TesseractBaseAPI} will only recognize text within this rectangle
- no external image manipulation required. Since we know that the
abstract is between the ``Abstract'' header and the ``Keywords''
tagline, we can easily find the coordinates of these using the
bounding boxes and then only recognize text within this area:

<<>>=
bb = GetBoxes(api)
idx = grep("Abstract|Keywords", rownames(bb))
bb[idx,"top"]
GetImageDims(api)

SetRectangle(api, 0, 950, 4000, 1800 - 950)
GetText(api, level = "textline")

#Reset rectangle
GetImageDims(api)

SetRectangle(api, 0, 0, 4013, 3210)
@ 

Many customizable variables which allow fine control of the OCR engine
are accessible through R via the \pkg{Rtesseract} package, including
pageSegMode, pageOrientation, language, white- and black-list
characters, custom user-added patterns and words, alternative OCR
engines, etc. The current settings for the tesseract OCR engine are
returned by \code{PrintVariables} (returns
\Sexpr{length(PrintVariables())} variables at the time of
writing). These variables can be adjusted via a call to
\code{SetVariables}.  Full documentation of user-adjustable variables
is available at
\url{https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc}.

Tesseract requires trained language files in order to operate. 
By default, \pkg{Rtesseract} searches the /usr/bin/local directory for
installed trained language files, but this can be overridden. The
current location where the API is searching for language data is
returned by \code{GetDataPath}. Since Tesseract allows users to create
trained data files for custom languages, the ability to specify the
path of the language files alleviates the need to place these language
data files in the default search location. More information on
training Tesseract and providing language files can be found at
\url{https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract}. 

%XXX This seems a little arcane and not necessarily relevant for this
%article, i.e. not necessarily % correct level.
% ME - I think it is OK for this paper

Lastly, we have found that some experimentation is required to settle
on the best set of customized variables for more difficult cases. By
creating persistent TesseractBaseAPI objects via the \code{tesseract}
function, two or more \code{TesseractBaseAPI}s can be created for the
same image, which allows you to compare the impact of various settings
to fine tune the OCR for individual cases. Once a suitable set of
adjustments have been found, these settings can be exported using
\code{PrintVariables}. These custom variables can then be easily set
using \code{SetVariables} or the \code{opts} argument in the
\code{tesseract} function.

% Looking at and changing options
<<>>=
#Querying the adjustable variables
v = PrintVariables()
v[grep("tessedit_char", names(v))]

@ 

\subsection{Writing directly to file}

\pkg{Rtesseract} includes funcitonality to export the results of OCR
to many conventional file types, including BoxText, HOcr/HTML , OSD
(Orientation and Script Detection), TSV (tab separated values), and
PDF. Of these, \code{toPDF} is unique in that it creates a searchable
PDF document, not a plain-text document.

\subsection{Metadata}

Lastly, \pkg{Rtesseract} allows users to access metadata about the OCR
engine and the input image. The current version of Tesseract can be
returned by \code{tesseractVersion}, while the capabilities for
reading various image formats via leptonica is provided by
\code{leptonicaImageFormats}. Information about the source image are
also accessible through R using the \code{GetInputName},
\code{GetImageInfo},\code{GetImageDims}, and
\code{GetSourceYResolution} functions.

\section{Installation}

In order to use \pkg{Rtesseract}, users must first have both Tesseract
and its dependency, Leptonica, installed. Tesseract is available from
\url{https://github.com/tesseract-ocr/} and Leptonica from
\url{https://github.com/DanBloomberg/leptonica}. Pre-compiled binaries
are available for most platforms for the current stable version
(v3.05). As previously mentioned \pkg{Rtesseract} also works with the
development version of Tesseract (4.00alpha) currently available from
\url{https://github.com/tesseract-ocr/tesseract/releases}. However, to
build Tesseract from source requires many additional pieces of
software, including leptonica v1.74+, automake, libtool, pkg-config,
aclocal, autoheader, and autoconf-archive. Additionally, users will
also need to install the training data for the language(s) used in the
documents to be processed.  Currently, there are pre-trained data sets
for 140+ languages available from
\url{https://github.com/tesseract-ocr}. Users can also provide their
own trained data. For more information about training Tesseract,
please see
\url{https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract}. \pkg{Rtesseract}
includes some functions that assist with training, including
\code{ReadBoxFile()}. Finally, the \pkg{Rtesseract} package itself can
be installed from source at
\url{https://github.com/duncantl/Rtesseract}.

% Different section title
\section{Conclusion}

\pkg{Rtesseract} provides both easy access to basic OCR functionality
for simple use-cases as well as access to low-level control parameters
for more advanced uses. By allowing recovery of additional information
generated by Tesseract, such as confidence levels and bounding boxes,
\pkg{Rtesseract} supports novel applications of inputting data from
images into R (e.g., spatial analysis of text). Leveraging free,
open-source software allows full integration of the work-flow of
text from images into R.

\bibliography{Rtesseract.bib}
